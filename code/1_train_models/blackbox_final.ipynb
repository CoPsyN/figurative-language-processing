{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c55e575-54d6-4a5a-bd33-53bbd14a0b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.cuda.set_device(1)\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faf08954-3151-4114-acad-c666127b4c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 22:07:45.263293: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import random, time, datetime, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForSequenceClassification \n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, accuracy_score\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd5accdd-21df-4eba-8763-1c1a9a71d18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 45\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab151dfa-35b2-4714-ab3e-2ab317e433d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10848, 4)\n",
      "0    6506\n",
      "1    2212\n",
      "2     884\n",
      "3     625\n",
      "4     621\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_binary</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can't believe my ex didn't pay his car note ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sarcasm_premise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>But then the paper would not find out about yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Idiom_premise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Last week my kid said some really mean things ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>CreativeParaphrase_premise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The gravy was so fatty, it made the meat taste...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Metaphor_premise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He pulls a giant disc out and flashes it like ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Simile_hypothesis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  label_binary  \\\n",
       "0  I can't believe my ex didn't pay his car note ...      0             0   \n",
       "1  But then the paper would not find out about yo...      0             0   \n",
       "2  Last week my kid said some really mean things ...      0             0   \n",
       "3  The gravy was so fatty, it made the meat taste...      0             0   \n",
       "4  He pulls a giant disc out and flashes it like ...      3             1   \n",
       "\n",
       "                       source  \n",
       "0             Sarcasm_premise  \n",
       "1               Idiom_premise  \n",
       "2  CreativeParaphrase_premise  \n",
       "3            Metaphor_premise  \n",
       "4           Simile_hypothesis  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/figlang_all.tsv\", sep=\"\\t\", encoding=\"utf-8\")\n",
    "print(df.shape)\n",
    "print(df[\"label\"].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c310fb-f590-49cb-8fc7-3cbbc022118a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8678, 4)\n",
      "0    5186\n",
      "1    1762\n",
      "2     714\n",
      "3     517\n",
      "4     499\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_binary</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That building looks very strong</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Simile_premise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was really agonizing over this decision for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Metaphor_premise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was so cheerful when I came outside this mor...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sarcasm_hypothesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Their language broadcasts us to believe them.</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Metaphor_hypothesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>For centuries, the ruler has made life like a ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Simile_hypothesis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  label_binary  \\\n",
       "0                    That building looks very strong      0             0   \n",
       "1  I was really agonizing over this decision for ...      0             0   \n",
       "2  I was so cheerful when I came outside this mor...      1             1   \n",
       "3      Their language broadcasts us to believe them.      4             1   \n",
       "4  For centuries, the ruler has made life like a ...      3             1   \n",
       "\n",
       "                source  \n",
       "0       Simile_premise  \n",
       "1     Metaphor_premise  \n",
       "2   Sarcasm_hypothesis  \n",
       "3  Metaphor_hypothesis  \n",
       "4    Simile_hypothesis  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../data/figlang_train.tsv\", sep=\"\\t\", encoding=\"utf-8\")\n",
    "print(df_train.shape)\n",
    "print(df_train[\"label\"].value_counts())\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e0d245-e317-4c7d-9ae5-d36ca626f76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2170, 4)\n",
      "0    1320\n",
      "1     450\n",
      "2     170\n",
      "4     122\n",
      "3     108\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_binary</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My considerate roommate cooked some meat with ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sarcasm_hypothesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The spy was very quiet</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Simile_premise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Look at lucy - very skinny and slender.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Idiom_premise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turns out, tag between super heroes can get li...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Simile_hypothesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Allister knows nothing about wine, he is a tee...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Metaphor_premise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  label_binary  \\\n",
       "0  My considerate roommate cooked some meat with ...      1             1   \n",
       "1                             The spy was very quiet      0             0   \n",
       "2            Look at lucy - very skinny and slender.      0             0   \n",
       "3  Turns out, tag between super heroes can get li...      3             1   \n",
       "4  Allister knows nothing about wine, he is a tee...      0             0   \n",
       "\n",
       "               source  \n",
       "0  Sarcasm_hypothesis  \n",
       "1      Simile_premise  \n",
       "2       Idiom_premise  \n",
       "3   Simile_hypothesis  \n",
       "4    Metaphor_premise  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"../data/figlang_test.tsv\", sep=\"\\t\", encoding=\"utf-8\")\n",
    "print(df_test.shape)\n",
    "print(df_test[\"label\"].value_counts())\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af11851-e6b1-4045-a9aa-5c970e86738c",
   "metadata": {},
   "source": [
    "# 1. Set the model to use\n",
    "\n",
    "**Uncomment one of the lines below to set the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4d9b35-cdc3-454f-b084-e5a0227b2aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL_NAME = \"bert-base-uncased\" \n",
    "#MODEL_NAME = \"roberta-base\" \n",
    "MODEL_NAME = \"xlnet-base-cased\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdec49a-ed0b-4de2-a2d3-ce3573cac77d",
   "metadata": {},
   "source": [
    "# 2. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3477386b-0fea-4fea-acc2-e97b8ccc6312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLNetTokenizerFast(name_or_path='xlnet-base-cased', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '<sep>', 'pad_token': '<pad>', 'cls_token': '<cls>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False), 'additional_special_tokens': ['<eop>', '<eod>']})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9bcc9b-88c2-4bb7-a793-5ad900cf89c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    2212\n",
       "2     884\n",
       "3     625\n",
       "4     621\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"label\"]!=0].value_counts(\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "372b3699-9685-485c-91c7-280f1e2006d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  59\n"
     ]
    }
   ],
   "source": [
    "test_max_len = 0\n",
    "\n",
    "for text in df[\"text\"]:\n",
    "    input_ids = tokenizer.encode(text, \n",
    "                                 add_special_tokens=True)\n",
    "    test_max_len = max(test_max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', test_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "601e34a1-4a56-4ce5-8df3-d47c07464463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximal length of input sequence\n",
    "MAX_LEN = test_max_len\n",
    "\n",
    "# Number of labels \n",
    "NUM_LABELS = 4\n",
    "\n",
    "# Specifying batch size: For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 16 \n",
    "\n",
    "# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dab42d9-e85d-4672-aff9-084d199f2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_and_label(df):\n",
    "    df_figlang_only = df.loc[df[\"label\"] != 0]\n",
    "        \n",
    "    # Re-map the label to start from 0, otherwise the training does not work:\n",
    "    label_map = {1: 0, \n",
    "                 2: 1,\n",
    "                 3: 2,\n",
    "                 4: 3}\n",
    "        \n",
    "    df_figlang_only[\"label\"] = df_figlang_only[\"label\"].map(label_map)\n",
    "        \n",
    "    X = df_figlang_only[\"text\"].values\n",
    "    y = df_figlang_only[\"label\"].values\n",
    "        \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "063383d6-c9ea-4da0-9751-c897ffc26edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "(3492,)\n",
      "(3492,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56420/2161799642.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_figlang_only[\"label\"] = df_figlang_only[\"label\"].map(label_map)\n"
     ]
    }
   ],
   "source": [
    "X, y = get_text_and_label(df_train)\n",
    "    \n",
    "print(np.unique(y))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ee9fa83-101c-4202-a530-6c55549ff0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(texts, tokenizer, max_len):\n",
    "    # Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every text...\n",
    "    for idx, text in enumerate(texts):\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            text,                      # Sentence to encode.\n",
    "            add_special_tokens = True, \n",
    "            padding = \"max_length\",\n",
    "            truncation = True,\n",
    "            max_length = max_len,\n",
    "            return_attention_mask = True,\n",
    "            return_tensors = 'pt')\n",
    "        \n",
    "        # Add the encoded sentence to the list.\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "    \n",
    "    # Convert to tensors.\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    \n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18d9f7a7-b97a-411f-8803-f09a56e8f483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training and validation set:\n",
      "torch.Size([2793, 59])\n",
      "torch.Size([2793])\n",
      "torch.Size([699, 59])\n",
      "torch.Size([699])\n",
      "\n",
      "Shape of attention masks:\n",
      "2793\n",
      "699\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_masks = tokenize(texts=X, tokenizer=tokenizer, max_len=MAX_LEN)\n",
    "labels = torch.tensor(y)\n",
    "\n",
    "# Use 80% for training and 20% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=1, test_size=0.2) \n",
    "\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels, random_state=1, test_size=0.2)\n",
    "\n",
    "print(\"Shape of training and validation set:\")\n",
    "print(train_inputs.shape)\n",
    "print(train_labels.shape)\n",
    "print(validation_inputs.shape)\n",
    "print(validation_labels.shape)\n",
    "\n",
    "print(\"\\nShape of attention masks:\")\n",
    "print(len(train_masks))\n",
    "print(len(validation_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1d88062-484a-491b-9698-c6a8b1fed12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd6d9791-1a53-4e40-bf9c-d221682bf410",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.bias', 'logits_proj.bias', 'sequence_summary.summary.weight', 'logits_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLNetForSequenceClassification(\n",
       "  (transformer): XLNetModel(\n",
       "    (word_embedding): Embedding(32000, 768)\n",
       "    (layer): ModuleList(\n",
       "      (0): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (activation_function): GELUActivation()\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (sequence_summary): SequenceSummary(\n",
       "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "    (first_dropout): Identity()\n",
       "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (logits_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model for sequence classification, the pretrained model with a single linear classification layer on top. \n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, \n",
    "    num_labels = NUM_LABELS, \n",
    "    output_attentions = False, \n",
    "    output_hidden_states = True,\n",
    ")\n",
    "    \n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f464793-41c9-41cf-9142-8dd61016ad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                  lr = 2e-5,   # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8   # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "642b6c3e-8c85-4623-8b18-23cfde9f7f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c763bdc-9b2a-4e9b-8777-f7721a8087c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "# Helper function for formatting elapsed times.\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7de5e9a-06f0-4a84-acd1-892cc2575f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    175.    Elapsed: 0:00:04.\n",
      "  Batch    80  of    175.    Elapsed: 0:00:06.\n",
      "  Batch   120  of    175.    Elapsed: 0:00:09.\n",
      "  Batch   160  of    175.    Elapsed: 0:00:12.\n",
      "\n",
      "  Average training loss: 0.41\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93969525\n",
      "  Macro-F1: 0.90989673\n",
      "  Validation took: 0:00:01\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    175.    Elapsed: 0:00:03.\n",
      "  Batch    80  of    175.    Elapsed: 0:00:06.\n",
      "  Batch   120  of    175.    Elapsed: 0:00:10.\n",
      "  Batch   160  of    175.    Elapsed: 0:00:15.\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epoch took: 0:00:17\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94679752\n",
      "  Macro-F1: 0.92114731\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    175.    Elapsed: 0:00:04.\n",
      "  Batch    80  of    175.    Elapsed: 0:00:08.\n",
      "  Batch   120  of    175.    Elapsed: 0:00:12.\n",
      "  Batch   160  of    175.    Elapsed: 0:00:15.\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epoch took: 0:00:16\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94395661\n",
      "  Macro-F1: 0.92215265\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch    40  of    175.    Elapsed: 0:00:03.\n",
      "  Batch    80  of    175.    Elapsed: 0:00:06.\n",
      "  Batch   120  of    175.    Elapsed: 0:00:09.\n",
      "  Batch   160  of    175.    Elapsed: 0:00:12.\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epoch took: 0:00:13\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95816116\n",
      "  Macro-F1: 0.93798701\n",
      "  Validation took: 0:00:02\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training vs. test \n",
    "    # (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a backward pass. \n",
    "        # PyTorch doesn't do this automatically because accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # This will return the loss (rather than the model output) because we have provided the `labels`.\n",
    "        # The documentation for this `model` function is here: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        outputs = model(b_input_ids, \n",
    "                    #token_type_ids=None, \n",
    "                    attention_mask=b_input_mask, \n",
    "                    labels=b_labels)\n",
    "        \n",
    "        # The call to `model` always returns a tuple, so we need to pull the loss value out of the tuple.\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can calculate the average loss at the end. \n",
    "        # `loss` is a Tensor containing a single value; the `.item()` function just returns the Python value from the tensor.\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    ### ----- Qi: add the following line to get detailed classification report -----\n",
    "    eval_predictions, eval_true_labels = [], []\n",
    "    ### END QI\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Add batch to GPU\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # Unpack the inputs from our dataloader\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            # This will return the logits rather than the loss because we have not provided labels.\n",
    "            # token_type_ids is the same as the \"segment ids\", which differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "            # The documentation for this `model` function is here: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            outputs = model(b_input_ids, \n",
    "                            #token_type_ids=None, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # Get the \"logits\" output by the model. The \"logits\" are the output values prior to applying an activation function like the softmax.\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        ### ----- Qi: add the following line to get detailed classification report -----\n",
    "        eval_predictions.append(logits)\n",
    "        eval_true_labels.append(label_ids) \n",
    "        ### END QI\n",
    "        \n",
    "        # Calculate the accuracy for this batch of test sentences.\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        # Accumulate the total accuracy.\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "\n",
    "        # Track the number of batches\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    ### ----- Qi: add the following line to get detailed classification report -----\n",
    "    eval_flat_predictions = np.concatenate(eval_predictions, axis=0) \n",
    "    eval_flat_predictions = np.argmax(eval_flat_predictions, axis=1).flatten() \n",
    "    eval_flat_true_labels = np.concatenate(eval_true_labels, axis=0) \n",
    "    ### END QI\n",
    "    \n",
    "    # Report the final accuracy for this validation run.\n",
    "    print(\"  Accuracy: {0:.8f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Macro-F1: {0:.8f}\".format(f1_score(eval_flat_true_labels, eval_flat_predictions, average=\"macro\")))###\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "    \n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe5a483-8b9c-44ed-a147-79b32a9dacd2",
   "metadata": {},
   "source": [
    "# 3. Get performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2750ef77-dc7f-43fc-b6d0-40faadadbc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]\n",
      "(850,)\n",
      "(850,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56420/2161799642.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_figlang_only[\"label\"] = df_figlang_only[\"label\"].map(label_map)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = get_text_and_label(df_test)\n",
    "\n",
    "print(np.unique(y_test))\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a80b029-cf19-4663-a0cf-309ad3327a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_masks = tokenize(texts=X_test, tokenizer=tokenizer, max_len=MAX_LEN)\n",
    "y_test = torch.tensor(y_test)\n",
    "\n",
    "# Set the batch size.  \n",
    "#batch_size = 32  ###\n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, y_test)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5cec869-c18e-4a26-ab74-c4a5efdb2f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 850 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "    # Telling the model not to compute or store gradients, saving memory and speeding up prediction\n",
    "    with torch.no_grad():\n",
    "        # Forward pass, calculate logit predictions\n",
    "        outputs = model(b_input_ids, \n",
    "                        #token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "    # Store predictions and true labels\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc3cfba0-af2c-45fe-9638-6364a52d6086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9647058824\n",
      "\n",
      "Macro-F1: 0.9489780575\n",
      "\n",
      "Detail:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       450\n",
      "           1       0.93      0.91      0.92       170\n",
      "           2       0.94      0.99      0.96       108\n",
      "           3       0.94      0.89      0.92       122\n",
      "\n",
      "    accuracy                           0.96       850\n",
      "   macro avg       0.95      0.95      0.95       850\n",
      "weighted avg       0.96      0.96      0.96       850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Print results:\n",
    "accuracy = accuracy_score(flat_true_labels, flat_predictions)\n",
    "f1 = f1_score(flat_true_labels, flat_predictions, average=\"macro\")\n",
    "\n",
    "print(\"Accuracy:\",  round(accuracy, 10))\n",
    "print()\n",
    "\n",
    "print(\"Macro-F1:\", round(f1, 10))\n",
    "print()\n",
    "\n",
    "print(\"Detail:\")\n",
    "print(classification_report(flat_true_labels, flat_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d8d35b-1762-4b63-8a07-0986615574b1",
   "metadata": {},
   "source": [
    "# 4. Save results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558a2b78-137a-40fb-b073-a110cf4bd6df",
   "metadata": {},
   "source": [
    "**Save confusion matrix:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ecebaa0-10a9-49fa-9d0e-b1e6f5fc51bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tick_labels = [\"sarcasm\", \"simile\", \"idiom\", \"metaphor\"]\n",
    "labels=[0, 2, 1, 3] # Group those with cues (sarcasm, simile) together, and those without cues (idiom, metaphor) together\n",
    "\n",
    "cm = confusion_matrix(flat_true_labels, flat_predictions, labels=labels) \n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", yticklabels=tick_labels, xticklabels=tick_labels, cmap=\"Greens\", annot_kws={'fontsize': 12})\n",
    "\n",
    "plt.savefig(\"../results/classification_results/confusion_matrix_testset_\" + MODEL_NAME + \".pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3566b291-7050-4f0e-9cea-ab67e03b4a7c",
   "metadata": {},
   "source": [
    "**Save classification report:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2baa5ab6-a38a-4c06-802b-bcd0e74707c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(flat_true_labels, flat_predictions, output_dict=True)\n",
    "df_result = pd.DataFrame(report).transpose()\n",
    "df_result.to_csv(\"../results/classification_results/classification_report_testset_\" + MODEL_NAME + \".tsv\", \n",
    "                sep = \"\\t\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87886ed-0627-48e3-83cb-395d2e8a1b11",
   "metadata": {},
   "source": [
    "**Save predicted labels:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e414feb1-e100-4a07-bcd2-0de1b49e66cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My considerate roommate cooked some meat with ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Turns out, tag between super heroes can get li...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Then as I gathered courage to go down I realiz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>It's absolutely fine that I got an older car f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>He was in a black mood.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>0</td>\n",
       "      <td>I was overjoyed when someone backed into my ne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>0</td>\n",
       "      <td>I almost crashed my car because the guy that c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>2</td>\n",
       "      <td>You can freely switch between them but the res...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>0</td>\n",
       "      <td>I was so delighted when I came home to find my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>3</td>\n",
       "      <td>He shouldered the costs for the accident.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>850 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text  pred\n",
       "0        0  My considerate roommate cooked some meat with ...     0\n",
       "1        2  Turns out, tag between super heroes can get li...     2\n",
       "2        1  Then as I gathered courage to go down I realiz...     1\n",
       "3        0  It's absolutely fine that I got an older car f...     0\n",
       "4        3                            He was in a black mood.     3\n",
       "..     ...                                                ...   ...\n",
       "845      0  I was overjoyed when someone backed into my ne...     0\n",
       "846      0  I almost crashed my car because the guy that c...     0\n",
       "847      2  You can freely switch between them but the res...     2\n",
       "848      0  I was so delighted when I came home to find my...     0\n",
       "849      3          He shouldered the costs for the accident.     3\n",
       "\n",
       "[850 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred = pd.DataFrame({\"label\": flat_true_labels,\n",
    "                        \"text\": X_test,\n",
    "                        \"pred\": flat_predictions})\n",
    "\n",
    "df_pred.to_csv(\"../results/classification_results/predicted_labels_testset_\" + MODEL_NAME + \".tsv\",\n",
    "               sep=\"\\t\", encoding=\"utf-8\", index=False)\n",
    "\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a008e-a486-44ad-a513-23ccc39beec5",
   "metadata": {},
   "source": [
    "**Save model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e14a06-7b02-4298-a279-b29d87f1532d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ../results/models/xlnet-base-cased-figlang\n"
     ]
    }
   ],
   "source": [
    "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
    "\n",
    "output_dir = '../results/models/' + MODEL_NAME + \"-figlang\" \n",
    "\n",
    "# Create output directory if needed\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
    "# They can then be reloaded using `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
